{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, pickle, re, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import tqdm\n",
    "\n",
    "DAY_LIMIT = 10\n",
    "\n",
    "# --- Settings ---\n",
    "CITIES = [\"ISTANBUL\"]\n",
    "cityname_map = {\n",
    "    \"ISTANBUL\": \"Istanbul\",\n",
    "    \"LONDON\": \"London\",\n",
    "    \"NY\": \"New York\"\n",
    "}\n",
    "\n",
    "city_colors = {\n",
    "    \"ISTANBUL\": \"#FFC300\",\n",
    "    \"LONDON\": \"#FF5733\",\n",
    "    \"NY\": \"#33AFFF\"\n",
    "}\n",
    "timezone_map = {\n",
    "    \"ISTANBUL\": pytz.timezone(\"Europe/Istanbul\"),\n",
    "    \"LONDON\": pytz.timezone(\"Europe/London\"),\n",
    "    \"NY\": pytz.timezone(\"America/New_York\")\n",
    "}\n",
    "\n",
    "highwayMap = {'motorway':0, 'highway':1, 'primary':2, 'secondary':3, 'tertiary':4, 'unclassified':5, 'residential':6, 'living_street': 7}\n",
    "theta = [100, 50, 20, 17, 10, 8, 8, 5]\n",
    "\n",
    "# --- Helpers ---\n",
    "def generate_shape_key(shape):\n",
    "    shape_str = json.dumps(shape, sort_keys=True)\n",
    "    return hashlib.md5(shape_str.encode()).hexdigest()\n",
    "\n",
    "def process_traffic_snapshot(traffic_data, roadKey_to_osmid, osmid_to_capacity):\n",
    "    flows, capacities = [], []\n",
    "    for seg in traffic_data['results']:\n",
    "        shape_data = seg['location']['shape']\n",
    "        jam_factor = seg['currentFlow']['jamFactor']\n",
    "        key = generate_shape_key(shape_data)\n",
    "        osmids_for_key = roadKey_to_osmid.get(key, [])\n",
    "        if not isinstance(osmids_for_key, list):\n",
    "            osmids_for_key = [osmids_for_key]\n",
    "        for osm_id in osmids_for_key:\n",
    "            capacity = osmid_to_capacity.get(osm_id, 0)\n",
    "            flows.append((jam_factor / 10.0) * capacity)\n",
    "            capacities.append(capacity)\n",
    "    flows, capacities = np.array(flows), np.array(capacities)\n",
    "    return float(np.sum(flows / capacities) / len(flows)) if len(flows) > 0 else 0.0\n",
    "\n",
    "def parse_timestamp_from_filename(filename):\n",
    "    match = re.search(r\"(?:traffic_data_|traffic__|traffic_)(\\d{8})_(\\d{6})\\.json\", filename)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Filename format not recognized: {filename}\")\n",
    "    date_str, time_str = match.group(1), match.group(2)\n",
    "    dt = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "    return dt.isoformat() + 'Z'\n",
    "\n",
    "# --- Main Loop ---\n",
    "city_hourly_data = {}\n",
    "\n",
    "for city in CITIES:\n",
    "    print(f\"Processing {city}\")\n",
    "    PATH = city\n",
    "    flow_folder = os.path.join(PATH, \"realFlowData\")\n",
    "    if not os.path.exists(flow_folder):\n",
    "        print(f\"Missing data folder for {city}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        with open(os.path.join(PATH, \"roadKey_to_osmid.pkl\"), \"rb\") as f:\n",
    "            roadKey_to_osmid = pickle.load(f)\n",
    "        with open(os.path.join(PATH, \"osmnx_subgraph.pkl\"), \"rb\") as f:\n",
    "            subG = pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Missing graph data for {city}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Set capacity\n",
    "    for edge in subG.edges:\n",
    "        highway = subG.edges[edge].get(\"highway\", \"unclassified\")\n",
    "\n",
    "        # Handle case where highway is a list like ['residential', 'unclassified']\n",
    "        if isinstance(highway, list):\n",
    "            highway = highway[0]  # Take the first type as primary\n",
    "\n",
    "        if highway not in highwayMap:\n",
    "            highway = \"unclassified\"\n",
    "\n",
    "        subG.edges[edge][\"capacity\"] = subG.edges[edge][\"length\"] * theta[highwayMap[highway]]\n",
    "\n",
    "\n",
    "    # Build capacity map\n",
    "    osmid_to_capacity = {}\n",
    "    for u, v, k, data in subG.edges(keys=True, data=True):\n",
    "        osmids = data.get('osmid', [])\n",
    "        if not isinstance(osmids, list):\n",
    "            osmids = [osmids]\n",
    "        for osm_id in osmids:\n",
    "            osmid_to_capacity[osm_id] = data.get(\"capacity\", 0)\n",
    "\n",
    "    flow_values = {}\n",
    "    processed_dates = set()\n",
    "\n",
    "    for fname in tqdm.tqdm(os.listdir(flow_folder)):\n",
    "        if not fname.endswith(\".json\"):\n",
    "            continue\n",
    "        try: \n",
    "            date = fname.split(\"_\")[1]\n",
    "            processed_dates.add(date)\n",
    "            \n",
    "            if(len(processed_dates)) > DAY_LIMIT:\n",
    "                break\n",
    "            \n",
    "            timestamp = parse_timestamp_from_filename(fname)\n",
    "\n",
    "            with open(os.path.join(flow_folder, fname), \"r\") as f:\n",
    "                td = json.load(f)\n",
    "            \n",
    "            flow_values[timestamp] = process_traffic_snapshot(td, roadKey_to_osmid, osmid_to_capacity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "\n",
    "    # Timezone conversion\n",
    "    local_tz = timezone_map[city]\n",
    "    sorted_keys = sorted(flow_values.keys())\n",
    "    sorted_datetimes = [datetime.strptime(ts, '%Y-%m-%dT%H:%M:%SZ') for ts in sorted_keys]\n",
    "    local_times = [pytz.utc.localize(dt).astimezone(local_tz) for dt in sorted_datetimes]\n",
    "    sorted_values = [flow_values[k] for k in sorted_keys]\n",
    "\n",
    "    # Hourly averaging\n",
    "    df = pd.DataFrame({\"timestamp\": local_times, \"value\": sorted_values})\n",
    "    df[\"hour\"] = pd.to_datetime(df[\"timestamp\"]).dt.hour\n",
    "    hourly_avg = df.groupby(\"hour\")[\"value\"].mean().reset_index()\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "    hourly_avg[\"normalized_value\"] = scaler.fit_transform(hourly_avg[[\"value\"]])\n",
    "    city_hourly_data[city] = hourly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame({\"timestamp\": local_times, \"value\": sorted_values})\n",
    "df_raw[\"timestamp\"] = pd.to_datetime(df_raw[\"timestamp\"])\n",
    "df_raw = df_raw.set_index(\"timestamp\")\n",
    "\n",
    "df_5min = df_raw[\"value\"].resample(\"5T\").mean().dropna().reset_index()\n",
    "df_5min[\"hour_fraction\"] = df_5min[\"timestamp\"].dt.hour + df_5min[\"timestamp\"].dt.minute / 60.0\n",
    "\n",
    "x_fit_base = df_5min[\"hour_fraction\"].values\n",
    "y_fit_base = df_5min[\"value\"].values\n",
    "\n",
    "poly = np.poly1d(np.polyfit(x_fit_base, y_fit_base, deg=23))\n",
    "\n",
    "# Generate 5-min resolution curve for plotting/comparison\n",
    "x_curve = np.arange(0, 24, 5 / 60.0)\n",
    "y_curve = poly(x_curve)\n",
    "\n",
    "df_hour = df_raw.resample(\"1H\").mean().dropna().reset_index()\n",
    "df_hour[\"hour_fraction\"] = df_hour[\"timestamp\"].dt.hour + df_hour[\"timestamp\"].dt.minute / 60.0\n",
    "\n",
    "df_10min = df_raw.resample(\"10T\").mean().dropna().reset_index()\n",
    "df_10min[\"hour_fraction\"] = df_10min[\"timestamp\"].dt.hour + df_10min[\"timestamp\"].dt.minute / 60.0\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_5min[\"hour_fraction\"], df_5min[\"value\"], '.', label=\"5-min Data\", alpha=0.4)\n",
    "plt.plot(df_hour[\"hour_fraction\"], df_hour[\"value\"], 'o', label=\"Hourly Avg\", markersize=5)\n",
    "plt.plot(df_10min[\"hour_fraction\"], df_10min[\"value\"], 's', label=\"10-min Avg\", markersize=4)\n",
    "plt.plot(x_curve, y_curve, '-', linewidth=2, label=\"Polynomial Fit (5-min Base)\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Jam Factor\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "for city, df in city_hourly_data.items():\n",
    "    x = df['hour'].values\n",
    "    y = df['value'].values\n",
    "    coeffs = np.polyfit(x, y, deg=4)  # or deg=1 or deg=5 depending on your needs\n",
    "    fitted_models[city] = np.poly1d(coeffs)\n",
    "\n",
    "    # Save the coefficients to file\n",
    "    folder = os.path.join(city)\n",
    "    os.makedirs(folder, exist_ok=True)  # ensure folder exists\n",
    "    np.save(os.path.join(folder, \"jam_model_poly.npy\"), coeffs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get data\n",
    "df = city_hourly_data[\"ISTANBUL\"]\n",
    "x = df['hour'].values\n",
    "y = df['value'].values\n",
    "\n",
    "# Fit 3rd degree polynomial\n",
    "coeffs = np.polyfit(x, y, deg=4)\n",
    "poly = np.poly1d(coeffs)\n",
    "\n",
    "# Evaluate fit\n",
    "x_fit = np.linspace(0, 23, 500)\n",
    "y_fit = poly(x_fit)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y, 'o', label='Original Data')\n",
    "plt.plot(x_fit, y_fit, '-', label='3rd Degree Polynomial Fit')\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Normalized Jam Factor\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "for city, df in city_hourly_data.items():\n",
    "    x = df['hour'].values\n",
    "    y = df['value'].values\n",
    "    coeffs = np.polyfit(x, y, deg=1)\n",
    "    fitted_models[city] = np.poly1d(coeffs)\n",
    "\n",
    "for city, poly_model in fitted_models.items():\n",
    "    folder = os.path.join(city)\n",
    "    np.save(os.path.join(folder, \"jam_model_poly.npy\"), poly_model.coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the coefficients array from the .npy file\n",
    "coeffs = np.load(PATH + \"/jam_model_poly.npy\")\n",
    "\n",
    "# Create a polynomial function from coefficients\n",
    "poly_model = np.poly1d(coeffs)\n",
    "\n",
    "# Now use it like a function\n",
    "hour = 13.5\n",
    "predicted_value = poly_model(hour)\n",
    "print(f\"Predicted jam factor at hour {hour}: {predicted_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80929010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scripts.TrafficModelWithJunctionRespect as tmjr\n",
    "import importlib\n",
    "importlib.reload(tmjr)\n",
    "\n",
    "# D3M\n",
    "sim = tmjr.simulator(G, np.array(theta), highwayMap)\n",
    "sim.simulate(np.array(M), 100, True, jamModel=poly_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
