{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pytz\n",
    "import requests\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString\n",
    "import networkx as nx\n",
    "import hashlib\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shape_key(shape):\n",
    "    \"\"\"Generate a unique hash key for a road shape based on its coordinates.\"\"\"\n",
    "    shape_str = json.dumps(shape, sort_keys=True)  # Convert to sorted JSON string\n",
    "    return hashlib.md5(shape_str.encode()).hexdigest()  # Create hash\n",
    "\n",
    "def process_traffic_snapshot(traffic_data, roadKey_to_osmid, osmid_to_capacity):\n",
    "    \"\"\"\n",
    "    For one traffic_data dict (one time snapshot), \n",
    "    compute the flow = capacity * (jamFactor / 10) for each segment, \n",
    "    then return the average flow (or sum, whichever you prefer).\n",
    "    \"\"\"\n",
    "    flows = []\n",
    "    capacities = []\n",
    "    \n",
    "    dividerCount = 0\n",
    "    for seg in traffic_data['results']:\n",
    "        shape_data = seg['location']['shape']\n",
    "        jam_factor = seg['currentFlow']['jamFactor']\n",
    "        \n",
    "        # Generate a shape-based key that matches what's used in roadKey_to_osmid\n",
    "        key = generate_shape_key(shape_data)  # You must define or adapt this.\n",
    "        \n",
    "        # Lookup OSM IDs for this shape key\n",
    "        # roadKey_to_osmid might return a single OSMID or a list\n",
    "        osmids_for_key = roadKey_to_osmid.get(key, [])\n",
    "        if not isinstance(osmids_for_key, list):\n",
    "            osmids_for_key = [osmids_for_key]  # unify to list\n",
    "        \n",
    "        # For each OSMID, find capacity and accumulate a flow measure\n",
    "        for osm_id in osmids_for_key:\n",
    "            dividerCount += 1\n",
    "            capacity = osmid_to_capacity.get(osm_id, 0)\n",
    "            capacities.append(capacity)\n",
    "            flow_value = (jam_factor / 10.0) * capacity\n",
    "            flows.append(flow_value)\n",
    "    \n",
    "    flows = np.array(flows)\n",
    "    capacities = np.array(capacities)\n",
    "\n",
    "    if len(flows) > 0:\n",
    "        return sum(flows / capacities) / len(flows)  # average\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "import datetime\n",
    "import re\n",
    "\n",
    "def parse_timestamp_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Given a filename like 'traffic_data_20250214_230741.json' or 'traffic__20250214_230741.json',\n",
    "    extract the date/time part and return an ISO-like string:\n",
    "    '2025-02-14T23:07:41Z'\n",
    "    \"\"\"\n",
    "    match = re.search(r\"(?:traffic_data_|traffic__|traffic_)(\\d{8})_(\\d{6})\\.json\", filename)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Filename format not recognized: {filename}\")\n",
    "\n",
    "    date_str, time_str = match.group(1), match.group(2)\n",
    "    dt = datetime.datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "    return dt.isoformat() + 'Z'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highwayMap = {'motorway':0, 'highway':1, 'primary':2, 'secondary':3, 'tertiary':4, 'unclassified':5, 'residential':6, 'living_street': 7}\n",
    "\n",
    "M   =       [[100, 50, 20, 17, 10, 8, 8, 5],\n",
    "            [55, 55, 22, 20, 15, 10, 10, 5],\n",
    "            [25, 25, 25, 23, 20, 15, 12, 5],\n",
    "            [25, 25, 25, 25, 23, 20, 13, 5],\n",
    "            [22, 22, 22, 22, 22, 21, 15, 5],\n",
    "            [21, 21, 21, 21, 21, 21, 17, 6],\n",
    "            [21, 21, 21, 21, 21, 21, 17, 6],\n",
    "            [18, 18, 18, 18, 18, 18, 18, 18]]\n",
    "\n",
    "theta       =   [100, 50, 20, 17, 10, 8, 8, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"ISTANBUL\"\n",
    "REAL_FLOW_DATA_FOLDER   = os.path.join(PATH, \"realFlowData\")\n",
    "\n",
    "roadKey_to_osmid_path = os.path.join(PATH, \"roadKey_to_osmid.pkl\")\n",
    "graph_path = os.path.join(PATH, \"osmnx_graph.pkl\")\n",
    "subgraph_path = os.path.join(PATH, \"osmnx_subgraph.pkl\")\n",
    "\n",
    "with open(roadKey_to_osmid_path, \"rb\") as f:\n",
    "    roadKey_to_osmid = pickle.load(f)\n",
    "\n",
    "with open(subgraph_path, \"rb\") as f:\n",
    "    subG = pickle.load(f)\n",
    "\n",
    "flowData = os.listdir(REAL_FLOW_DATA_FOLDER)\n",
    "\n",
    "for edge in subG.edges:\n",
    "    try:\n",
    "        highwayName = edge.attrib[\"highway\"]\n",
    "\n",
    "        highwayName = highwayName.replace(\"_link\", \"\")  \n",
    "\n",
    "        if highwayName.startswith(\"trunk\"):\n",
    "            highwayName = \"primary\"\n",
    "\n",
    "        if highwayName.startswith(\"motorway\"):\n",
    "            highwayName = \"primary\"\n",
    "        \n",
    "        if highwayName.startswith(\"living_street\"):\n",
    "            highwayName = \"residential\"\n",
    "\n",
    "        if type(highwayName) is list:\n",
    "            highwayName = highwayName[0]\n",
    "\n",
    "        if highwayName not in highwayMap.keys():\n",
    "            highwayName = \"residential\"\n",
    "\n",
    "        if highwayName.startswith(\"unclassified\"):\n",
    "            highwayName = \"residential\"\n",
    "\n",
    "    except:\n",
    "        highwayName = \"residential\"\n",
    "    \n",
    "    subG.edges[edge]['highway'] = highwayName\n",
    "\n",
    "    subG.edges[edge][\"capacity\"] = subG.edges[edge][\"length\"] * theta[highwayMap[subG.edges[edge][\"highway\"]]]\n",
    "\n",
    "timezone_map = {\n",
    "    \"ISTANBUL\": pytz.timezone(\"Europe/Istanbul\"),\n",
    "    \"LONDON\": pytz.timezone(\"Europe/London\"),\n",
    "    \"NY\": pytz.timezone(\"America/New_York\"),\n",
    "    \"TOKYO\": pytz.timezone(\"Asia/Tokyo\"),\n",
    "    \"TOKYO2\": pytz.timezone(\"Asia/Tokyo\"),\n",
    "    \"LONDON2\": pytz.timezone(\"Europe/London\"),\n",
    "    \"BERLIN\": pytz.timezone(\"Europe/Berlin\"),\n",
    "}\n",
    "\n",
    "print(\"Generating all flow data, date->avgFlow\")\n",
    "\n",
    "osmid_to_capacity = {}\n",
    "\n",
    "for u, v, k, data in subG.edges(keys=True, data=True):\n",
    "    edge_osmid = data.get('osmid')\n",
    "    capacity = data.get('capacity', 0)\n",
    "    \n",
    "    if edge_osmid is None:\n",
    "        continue\n",
    "    if isinstance(edge_osmid, list):\n",
    "        for osm in edge_osmid:\n",
    "            osmid_to_capacity[osm] = capacity\n",
    "    else:\n",
    "        osmid_to_capacity[edge_osmid] = capacity\n",
    "\n",
    "all_flow_data = {}\n",
    "\n",
    "for filename in flowData:\n",
    "    timestamp_str = parse_timestamp_from_filename(filename)\n",
    "    \n",
    "    with open(os.path.join(REAL_FLOW_DATA_FOLDER, filename), \"r\") as f:\n",
    "        try:\n",
    "            td = json.load(f)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_flow = process_traffic_snapshot(td, roadKey_to_osmid, osmid_to_capacity)\n",
    "    \n",
    "    all_flow_data[timestamp_str] = avg_flow\n",
    "\n",
    "\n",
    "sorted_keys = sorted(all_flow_data.keys())\n",
    "sorted_values = [all_flow_data[k] for k in sorted_keys]\n",
    "\n",
    "sorted_values = np.array(sorted_values)\n",
    "\n",
    "date_format = '%Y-%m-%dT%H:%M:%SZ'\n",
    "sorted_datetimes = [datetime.datetime.strptime(k, date_format) for k in sorted_keys]\n",
    "\n",
    "istanbulTimeZone = timezone_map[PATH]\n",
    "timeZone = timezone_map[PATH]\n",
    "convertedTimezones = []\n",
    "\n",
    "for dt in sorted_datetimes:\n",
    "    ist_time = istanbulTimeZone.localize(dt)\n",
    "    utc_time = ist_time.astimezone(pytz.utc)\n",
    "\n",
    "    local_time = utc_time.astimezone(timeZone)\n",
    "    convertedTimezones.append(local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytz\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATHS = [\"ISTANBUL\"]\n",
    "\n",
    "\n",
    "# Timezone mapping\n",
    "timezone_map = {\n",
    "    \"ISTANBUL\": pytz.timezone(\"Europe/Istanbul\"),\n",
    "    \"LONDON\": pytz.timezone(\"Europe/London\"),\n",
    "    \"NY\": pytz.timezone(\"America/New_York\"),\n",
    "    \"TOKYO\": pytz.timezone(\"Asia/Tokyo\"),\n",
    "    \"TOKYO2\": pytz.timezone(\"Asia/Tokyo\"),\n",
    "    \"LONDON2\": pytz.timezone(\"Europe/London\"),\n",
    "    \"BERLIN\": pytz.timezone(\"Europe/Berlin\"),\n",
    "}\n",
    "# Dictionary to store morning and night filenames for each city\n",
    "city_file_lists = {city: {\"morning\": [], \"night\": []} for city in PATHS}\n",
    "\n",
    "def parse_timestamp_from_filename(filename):\n",
    "    \"\"\"Extracts the datetime from the filename assuming format: traffic_data_YYYYMMDD_HHMMSS.json\"\"\"\n",
    "    match = re.search(r\"(?:traffic_data_|traffic__|traffic_)(\\d{8})_(\\d{6})\\.json\", filename)\n",
    "    if match:\n",
    "        date_part = match.group(1)  # YYYYMMDD\n",
    "        time_part = match.group(2)  # HHMMSS\n",
    "        return f\"{date_part}T{time_part}Z\"\n",
    "    return None\n",
    "\n",
    "for PATH in tqdm(PATHS):\n",
    "    # Define data path\n",
    "    REAL_FLOW_DATA_FOLDER = os.path.join(PATH, \"realFlowData\")\n",
    "    \n",
    "    # List all traffic data files\n",
    "    flowData = os.listdir(REAL_FLOW_DATA_FOLDER)\n",
    "\n",
    "    for filename in flowData:\n",
    "        # 1) Parse timestamp from filename\n",
    "        timestamp_str = parse_timestamp_from_filename(filename)\n",
    "        if not timestamp_str:\n",
    "            continue\n",
    "\n",
    "        # 2) Convert filename timestamp (assumed Istanbul time) to UTC\n",
    "        istanbul_time = datetime.datetime.strptime(timestamp_str, \"%Y%m%dT%H%M%SZ\")\n",
    "        istanbul_tz = pytz.timezone(\"Europe/Istanbul\")\n",
    "        istanbul_time = istanbul_tz.localize(istanbul_time)\n",
    "        utc_time = istanbul_time.astimezone(pytz.utc)\n",
    "\n",
    "        # 3) Convert UTC to the local timezone of the city\n",
    "        local_time = utc_time.astimezone(timezone_map[PATH])\n",
    "        local_hour = local_time.hour\n",
    "\n",
    "        # 4) Categorize filenames into morning (09:00-19:00) or night (19:00-09:00)\n",
    "        if 9 <= local_hour < 19:\n",
    "            city_file_lists[PATH][\"morning\"].append(filename)\n",
    "        else:\n",
    "            city_file_lists[PATH][\"night\"].append(filename)\n",
    "\n",
    "# Now city_file_lists contains only the filenames categorized correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytz\n",
    "import datetime\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "PATHS = [\"ISTANBUL\"]\n",
    "\n",
    "# Timezone mapping\n",
    "timezone_map = {\n",
    "    \"ISTANBUL\": pytz.timezone(\"Europe/Istanbul\"),\n",
    "    \"LONDON\": pytz.timezone(\"Europe/London\"),\n",
    "    \"NY\": pytz.timezone(\"America/New_York\"),\n",
    "}\n",
    "\n",
    "# Dictionary to store categorized filenames\n",
    "city_file_lists = {city: {\"days\": {}} for city in PATHS}\n",
    "\n",
    "def parse_timestamp_from_filename(filename):\n",
    "    \"\"\"Extracts the datetime from the filename assuming format: traffic_data_YYYYMMDD_HHMMSS.json\"\"\"\n",
    "    match = re.search(r\"(?:traffic_data_|traffic__|traffic_)(\\d{8})_(\\d{6})\\.json\", filename)\n",
    "\n",
    "    if match:\n",
    "        date_part = match.group(1)  # YYYYMMDD\n",
    "        time_part = match.group(2)  # HHMMSS\n",
    "        return f\"{date_part}T{time_part}Z\"\n",
    "    return None\n",
    "\n",
    "for PATH in tqdm(PATHS):\n",
    "    # Define data path\n",
    "    REAL_FLOW_DATA_FOLDER = os.path.join(PATH, \"realFlowData\")\n",
    "    \n",
    "    # List all traffic data files\n",
    "    flowData = os.listdir(REAL_FLOW_DATA_FOLDER)\n",
    "\n",
    "    for filename in flowData:\n",
    "        # 1) Parse timestamp from filename\n",
    "        timestamp_str = parse_timestamp_from_filename(filename)\n",
    "        if not timestamp_str:\n",
    "            continue\n",
    "\n",
    "        # 2) Convert filename timestamp (assumed Istanbul time) to UTC\n",
    "        istanbul_time = datetime.datetime.strptime(timestamp_str, \"%Y%m%dT%H%M%SZ\")\n",
    "        istanbul_tz = pytz.timezone(\"Europe/Istanbul\")\n",
    "        istanbul_time = istanbul_tz.localize(istanbul_time)\n",
    "        utc_time = istanbul_time.astimezone(pytz.utc)\n",
    "\n",
    "        # 3) Convert UTC to the local timezone of the city\n",
    "        local_time = utc_time.astimezone(timezone_map[PATH])\n",
    "        local_hour = local_time.hour\n",
    "        local_date = local_time.strftime(\"%Y-%m-%d\")  # Store date separately\n",
    "\n",
    "        # 4) Ensure \"days\" dictionary exists for that city\n",
    "        if local_date not in city_file_lists[PATH][\"days\"]:\n",
    "            city_file_lists[PATH][\"days\"][local_date] = {\"morning\": [], \"night\": []}\n",
    "\n",
    "        # 5) Categorize filenames into morning (09:00-19:00) or night (19:00-09:00)\n",
    "        if 9 <= local_hour < 19:\n",
    "            city_file_lists[PATH][\"days\"][local_date][\"morning\"].append(filename)\n",
    "        else:\n",
    "            city_file_lists[PATH][\"days\"][local_date][\"night\"].append(filename)\n",
    "\n",
    "    # Define the output pickle file path\n",
    "    pickle_filename = \"city_file_lists.pkl\"\n",
    "\n",
    "    # Save the dictionary as a pickle file\n",
    "    with open(os.path.join(PATH, pickle_filename), \"wb\") as f:\n",
    "        pickle.dump(city_file_lists, f)\n",
    "\n",
    "    print(f\"Saved city_file_lists to {pickle_filename}\")\n",
    "\n",
    "\n",
    "# Now city_file_lists contains files categorized by city → date → morning/night.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the output pickle file path\n",
    "pickle_filename = \"city_file_lists.pkl\"\n",
    "\n",
    "# Save the dictionary as a pickle file\n",
    "with open(os.path.join(pickle_filename), \"wb\") as f:\n",
    "    pickle.dump(city_file_lists, f)\n",
    "\n",
    "print(f\"Saved city_file_lists to {pickle_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
